## 写在前面
公司内部目前使用grafa和elk但是老大提出需求说要搞一套自动报警,他的设想是通过刷取es的数据然后自己进行判断来发送报警邮件,这件事交给我来做,所以顺着他的思路进行调研

## 我的发现
在调研的过程中从以下几个渠道进行查找
- 开源软件
- kibana或者grafa自带的监控报警插件
- 手动编码实现

实现的方式有上述三种,接下来我会分别描述上述三种情况需要的实现过程

### 报警系统开源软件
专门负责对接各种中间件,采集数据对数据实时分析并且提供报警等服务.
<div style="color:red">业界代表:zibbix</div>
#### 优点
- 专门负责报警管理功能全面
- 提供自己的数据采集工具
- 可以查看历史数据
- 提供图形化展示页面
- 拥有权限管理

#### 缺点
- 大规模下有性能压力
- 上手难度大,不适合小型项目
- 需要专业的运维知识


#### 总结
基于以上几点我认为仅开发这方面的需求无需使用zibbix过于繁重,而且对于nginx日志分析不是很友好


### 基于现有的监控平台自带的报警
目前公司使用的监控工具有zabbix,grafa,kibana这些工具(grafa,kibana)都自带有报警功能,而且后两者均是基于elasticsearch进行工作的
<div style="color:red">业界代表:kibana,grafa</div>
#### 优点
- 无需集成其他中间件
- 操作简单易于上手
- grafa提供优秀的图形化展示
- kibana属于ELK套件,对多种中间件都有自己的modules可以直接使用
- grafa可以对接多种数据源
- 拥有权限管理
- kibana可以集中处理服务日志并提供良好的查看工具(特点)

#### 缺点
- kibana没有权限管理,并且图形化界面不是很美观
- garfa报警功能比较单一
- 需要配合ELK套件使用


#### 总结
目前公司内部已经开始使用kibana和grafa进行监控了,根据我的调查目前运维已经配置了grafa的一些报警,只不过没有针对我们的服务进行定制化配置


### 手动编码实现
对于手动编码而言其实是一个弹性范围很大的工作,长远考虑可以设计一个监控报警平台专门负责监控公司内部中间件使用情况,以及各服务的运行状态,全链路跟踪,或者是多借点服务日志采集等等吧只要公司给予足够的资源都是有望实现的.但是对于目前的需求而言个人认为不适合.

#### 不适合手动编码实现的原因
- 需求不是很明确,缺少详细的规划
- 对于目前的需求可以使用现有的监控系统快速实现
- 手动编码实现的高度定制化无法体现在我们目前的需求上
- 相对前两中实现方式,手动编码消耗人力资源相对高一点
- 不稳定性太高,各种坑以及转瞬即逝的需求


<div style="color:red;font-size:30px;font-weight;">这才是总结</div>
根据调查结果目前准备使用第二种解决方案


### 效果展示

#### 并发测试
监控目标为/ns/* 也就是搜索服务的所有接口
![](https://ws4.sinaimg.cn/large/006tNc79ly1fz9zy79nnpj30o60va760.jpg)

#### 发出报警
配置的是如果每2秒并发量超过15就报警,如果并发量恢复阈值后超过15秒监控将继续处于可报警状态(为了测试简单点)
![](https://ws3.sinaimg.cn/large/006tNc79ly1fza02t4lf7j30qt0aw754.jpg)

#### 收到通知
报警消息可发送到邮件列表或者钉钉,钉钉消息延迟约15秒(计算方式为请求开始到收到报警)
![](https://ws2.sinaimg.cn/large/006tNc79ly1fz9zyfcrdvj30t20awdgk.jpg)

### 测试相关工具
- [grafa](http://192.168.100.47:3000/d/pMPIUAQik/path-test?panelId=2&fullscreen&edit&tab=alert&refresh=5s&orgId=1): docker临时起的
- [elasticsearch](http://192.168.100.46:9200/): docker临时起的  账号:admin  密码:shuaizheng1995
- nginx: 22服务的nginx
- filebeat: 22服务的filebeat
- base-search: 搜索服务用与测试
- dingding: 自己的群